{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_values = ['count','registered','casual']\n",
    "\n",
    "# no categories included\n",
    "with_categories = False\n",
    "\n",
    "# Set datetime column as index to work with data based on Date/Time\n",
    "df = pd.read_csv('train.csv', parse_dates=['datetime'],index_col=0)\n",
    "df_test = pd.read_csv('test.csv', parse_dates=['datetime'],index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index.min(),df.index.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.index.min(),df_test.index.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['2011-01']['count'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding out how many hours we need to predict in a month using test.csv data file\n",
    "hours_to_predict = []\n",
    "print ('Check maximum hours we need to predict')\n",
    "\n",
    "predict_window = df_test.groupby([df_test.index.year,df_test.index.month])\n",
    "for i,x in predict_window:\n",
    "    delta = x.index.max() - x.index.min() \n",
    "    hours = np.ceil(delta.total_seconds()/3600)\n",
    "    hours_to_predict.append(hours)\n",
    "    print (\"{0}, Hours:{1}\".format(i, hours))\n",
    "\n",
    "print (\"Maximum Prediction Length in Hours: \", np.max(hours_to_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq='H' predict hourly rental count\n",
    "# 12 days of hourly forecast \n",
    "prediction_length = 288 \n",
    "\n",
    "# choose setting context same as prediction length as a starting point\n",
    "# controls how far in the past the network can see\n",
    "context_length = 288"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_predict_max = pd.Timestamp(\"2012-12-31 23:00:00\", freq=freq) # 2012-12-31 23:00 alt way..pd.datetime(2012,12,31,23,0,0)\n",
    "\n",
    "dt_dataset_start_time = pd.Timestamp(\"2011-01-01 00:00:00\", freq=freq)\n",
    "dt_dataset_end_time = pd.Timestamp(\"2012-12-19 23:00:00\", freq=freq)\n",
    "\n",
    "dt_train_range = (dt_dataset_start_time,\n",
    "                  dt_dataset_end_time - datetime.timedelta(hours=12*24) )\n",
    "\n",
    "# Use entire data for testing\n",
    "\n",
    "dt_test_range = (dt_dataset_start_time, \n",
    "                 dt_dataset_end_time) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_predict_max,dt_predict_max+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if there are gaps in timesteps\n",
    "def is_missing_steps(df,start,end,freq='D'):\n",
    "    dt_range = pd.date_range(start=start,end=end,freq=freq)\n",
    "    return not dt_range.equals(df[start:end].index)\n",
    "\n",
    "def get_missing_steps(df,start,end,freq='D'):\n",
    "    dt_range = pd.date_range(start=start,end=end,freq=freq)\n",
    "    return dt_range.difference(df[start:end].index)    \n",
    "\n",
    "# List timeseries with only NaNs\n",
    "\n",
    "def timeseries_with_only_nans(df):\n",
    "    l = []\n",
    "    for col in df.columns:\n",
    "        if pd.isna(df[col].min()):\n",
    "            #print (col)\n",
    "            l.append(col)\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_missing_steps(df, '2011-01-01 00:00:00', '2011-01-19 23:00:00','H')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_missing_steps(df, '2011-01-01 00:00:00', '2011-01-19 23:00:00','H')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['2011-01-02 00:00:00':'2011-01-02 14:00:00']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['2011-01-02 00:00:00':'2011-01-02 14:00:00']['count'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.resample('1h').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['2011-01-02 00:00:00':'2011-01-02 14:00:00']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['2011-01-02 00:00:00':'2011-01-02 14:00:00']['count'].plot(title='Missing values in training data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['2012-01':'2012-02']['count'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[dt_test_range[0]:dt_test_range[1]]['count'].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_test_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_train_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series_test = []\n",
    "time_series_training = []\n",
    "\n",
    "for target in target_values:\n",
    "    time_series_test.append(df[dt_test_range[0]:dt_test_range[1]][target])\n",
    "    time_series_training.append(df[dt_train_range[0]:dt_train_range[1]][target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series_test[0][:5],time_series_test[1][:5],time_series_test[2][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series_training[0][:5],time_series_training[1][:5],time_series_training[2][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series_test[0].plot(label='test')\n",
    "time_series_training[0].plot(label='train')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_target(ts):\n",
    "    return [x if np.isfinite(x) else \"NaN\" for x in ts]  \n",
    "\n",
    "def encode_dynamic_feat(dynamic_feat):  \n",
    "    l = []\n",
    "    for col in dynamic_feat:\n",
    "        assert (not dynamic_feat[col].isna().any()), col  + ' has NaN'             \n",
    "        l.append(dynamic_feat[col].tolist())\n",
    "    return l\n",
    "\n",
    "def series_to_obj(ts, cat=None, dynamic_feat=None):\n",
    "    obj = {\"start\": str(ts.index[0]), \"target\": encode_target(ts)}\n",
    "    if cat is not None:\n",
    "        obj[\"cat\"] = cat\n",
    "    if dynamic_feat is not None:\n",
    "        obj[\"dynamic_feat\"] = encode_dynamic_feat(dynamic_feat)\n",
    "    return obj\n",
    "\n",
    "def series_to_jsonline(ts, cat=None, dynamic_feat=None):\n",
    "    return json.dumps(series_to_obj(ts, cat, dynamic_feat))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(time_series_training[0][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_to_obj(time_series_training[0][:5],[0] if with_categories else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_to_jsonline(time_series_training[0][:5],[0] if with_categories else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = \"utf-8\"\n",
    "cat_idx = 0\n",
    "\n",
    "train_file_name = \"train.json\"\n",
    "test_file_name = \"test.json\"\n",
    "\n",
    "if with_categories:\n",
    "    train_file_name = \"train_with_categories.json\"\n",
    "    test_file_name = \"test_with_categories.json\"\n",
    "\n",
    "with open(train_file_name, 'wb') as fp:\n",
    "    for ts in time_series_training:\n",
    "        fp.write(series_to_jsonline(ts,[cat_idx] if with_categories else None).encode(encoding))\n",
    "        fp.write('\\n'.encode(encoding))\n",
    "        cat_idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_idx = 0\n",
    "with open(test_file_name, 'wb') as fp:\n",
    "    for ts in time_series_test:\n",
    "        fp.write(series_to_jsonline(ts,[cat_idx] if with_categories else None).encode(encoding))\n",
    "        fp.write('\\n'.encode(encoding))\n",
    "        cat_idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('all_data.csv',index=True,index_label='datetime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ts in time_series_test:\n",
    "    print (len(ts),ts.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ts in time_series_training:\n",
    "    print (len(ts),ts.name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
